{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The sun was shining brightly in the clear blue sky, and a gentle breeze rustled the leaves of the tall trees. People were out enjoying the beautiful weather, some sitting in the park, others taking a leisurely stroll along the riverbank. Children were playing games, and laughter filled the air.\n",
    "\n",
    "As the day turned into evening, the temperature started to drop, and the sky transformed into a canvas of vibrant colors. Families gathered for picnics, and the smell of barbecues wafted through the air. It was a perfect day for a picnic by the lake.\n",
    "\n",
    "In the distance, you could hear the sound of live music coming from a local band, and people began to gather around the stage to enjoy the performance. The atmosphere was electric, and the music had everyone swaying to the beat.\n",
    "\n",
    "As the stars began to twinkle in the night sky, the crowd grew even larger, and the festivities continued well into the night. It was a day filled with joy, laughter, and memories that would last a lifetime.\n",
    "\n",
    "The ancient castle stood on a hill, its towering spires reaching up towards the sky. The castle had a rich history, and its stone walls had witnessed countless battles and royal intrigues. Tourists from all over the world flocked to explore its mysteries.\n",
    "\n",
    "Inside the castle, you could find grand halls adorned with magnificent tapestries and chandeliers. The air was thick with the scent of history, and the creaking of old wooden floors echoed in the corridors. The castle's library housed an impressive collection of books, some dating back centuries.\n",
    "\n",
    "As you ventured further into the castle, you would discover hidden chambers and secret passages. Legends spoke of a hidden treasure buried somewhere within its walls, waiting to be found by a brave adventurer.\n",
    "\n",
    "Outside the castle, a vast moat surrounded it, and a drawbridge provided access to the outside world. Beyond the moat, a lush forest stretched as far as the eye could see, inviting exploration and adventure.\n",
    "\n",
    "The village at the base of the hill relied on the castle for protection and trade. The townspeople were friendly and welcoming, and their stories were filled with folklore and local legends.\n",
    "\n",
    "At night, the castle's windows lit up with a warm, inviting glow, making it look like something out of a fairy tale. It was a place where history and fantasy intertwined, a place where dreams and reality converged.\n",
    "\n",
    "In the heart of the bustling city, the streets were alive with the sounds of traffic and the chatter of people going about their daily lives. Skyscrapers reached towards the heavens, their glass facades reflecting the vibrant energy of the metropolis.\n",
    "\n",
    "Street vendors sold a variety of goods, from sizzling hot dogs to handmade jewelry. The aroma of freshly brewed coffee wafted from the corner cafes, where patrons sipped their drinks while watching the world go by.\n",
    "\n",
    "Amid the urban chaos, a beautiful park provided a serene escape. Tall trees offered shade, and a tranquil pond was home to ducks and swans. The park's paths were lined with benches where people could sit and read, or simply enjoy the calm in the midst of the urban storm.\n",
    "\n",
    "The city's cultural scene was rich and diverse, with theaters showcasing the latest plays and art galleries displaying works from local and international artists. The symphony orchestra filled the air with music, and museums held treasures from various eras.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = []\n",
    "for sentence in text.split('.'):\n",
    "    tokenized_sent = tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1,len(tokenized_sent)):\n",
    "        input_seq.append(tokenized_sent[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "pad_input_seq = pad_sequences(input_seq , maxlen=max_len , padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   1,  61],\n",
       "       [  0,   0,   0, ...,   1,  61,   7],\n",
       "       [  0,   0,   0, ...,  61,   7,  62],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 305, 306,  10],\n",
       "       [  0,   0,   0, ..., 306,  10, 307],\n",
       "       [  0,   0,   0, ...,  10, 307, 308]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0,   0,   1],\n",
       "       [  0,   0,   0, ...,   0,   1,  61],\n",
       "       [  0,   0,   0, ...,   1,  61,   7],\n",
       "       ...,\n",
       "       [  0,   0,   0, ..., 304, 305, 306],\n",
       "       [  0,   0,   0, ..., 305, 306,  10],\n",
       "       [  0,   0,   0, ..., 306,  10, 307]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pad_input_seq[:,:-1] #removing last element \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 61,   7,  62,  63,   8,   1,  64,  65,  14,   2,   3,  66,  67,\n",
       "        68,   1,  69,   4,   1,  33,  34,   9,  35,  70,   1,  36,  71,\n",
       "        37,  72,   8,   1,  38,  73,  74,   3,  75,  76,  77,   1,  78,\n",
       "         9,  80,  81,   2,  39,  16,   1,  17,   1,  24,  82,  18,  83,\n",
       "         1,  84,  85,   5,  86,   2,   1,  14,  87,  18,   3,  88,   4,\n",
       "        40,  89,  91,  25,  92,   2,   1,  93,   4,  94,  41,  95,   1,\n",
       "        17,   7,   3,  96,  24,  25,   3,  97,  26,   1,  98,   1,  99,\n",
       "        19,  20, 100,   1, 101,   4, 102,  27, 103,  10,   3,  28, 104,\n",
       "         2,  15,  42,   5, 105, 106,   1, 107,   5,  43,   1, 108, 109,\n",
       "         7, 110,   2,   1,  27,  29, 111, 112,   5,   1, 113,   1, 114,\n",
       "        42,   5, 115,   8,   1,  30,  14,   1, 116, 117, 118, 119,   2,\n",
       "         1, 120, 121, 122,  18,   1,  30,   7,   3,  24,  16,   6, 123,\n",
       "        39,   2, 124, 125,  44, 126,   3, 127, 128,  11, 129,  45,   3,\n",
       "        46,  21, 130, 131, 132,  47,  48,   1,  14,  11,  29,   3,  49,\n",
       "        31,   2,  21, 133,  50,  29, 134, 135, 136,   2, 137, 138,  10,\n",
       "       140, 141,   1,  32, 142,   5, 143,  21, 144,   1,  11,  19,  20,\n",
       "       146, 147, 148, 149,   6, 150, 151,   2, 152,  17,   7, 153,   6,\n",
       "         1, 154,   4,  31,   2,   1, 155,   4, 156, 157, 158, 159,   8,\n",
       "         1, 160,  51, 161, 162, 163, 164, 165,   4, 166,  37, 167, 168,\n",
       "       169,  19, 170, 171,  18,   1,  11,  19,  44, 172,  52, 173,   2,\n",
       "       174, 175, 176,   4,   3,  52, 177, 178, 179, 180,  21,  50, 181,\n",
       "         5, 182, 183,  26,   3, 184, 185,   1,  11,   3, 186,  55, 187,\n",
       "        13,   2,   3, 188,  56, 189,   5,   1,  54,  32,   1,  55,   3,\n",
       "       191, 192, 193,  12, 194,  12,   1, 195,  20, 196,  57, 197,   2,\n",
       "       198, 199,  58,   1, 200,   4,   1,  46, 201,  45,   1,  11,  25,\n",
       "       202,   2, 203, 204,   9, 205,   2, 206,   2,  22, 207,   9,  16,\n",
       "         6, 208,   2,  28,  53,  30,   1,  51, 209, 210,  47,   6,   3,\n",
       "       211,  57, 212, 213,  13, 214, 215, 216,  35,   4,   3, 217, 218,\n",
       "         7,   3,  59,  23,  31,   2, 219, 220,   3,  59,  23, 221,   2,\n",
       "       222, 223,   1, 224,   4,   1, 225, 226,   1, 227,   9, 228,   6,\n",
       "         1, 229,   4, 230,   2,   1, 231,   4,  15, 232, 233,  22, 234,\n",
       "       235, 237,  48,   1, 238,  22, 239, 240, 241,   1,  40, 242,   4,\n",
       "         1, 243, 245, 246,   3, 247,   4, 248,  10, 249, 250, 251,   5,\n",
       "       252, 253, 254,   4, 255, 256, 257,  41,  10,   1, 258, 259,  23,\n",
       "       260, 261,  22, 262, 263, 264,   1,  32, 265,  26,   1,  60, 267,\n",
       "         3,  36,  38,  56,   3, 268, 269,  34, 270, 271,   2,   3, 272,\n",
       "       273,   7, 274,   5, 275,   2, 276, 277, 278,   9, 279,   6, 280,\n",
       "        23,  15,  20, 281,   2, 282, 283, 284,  43,   1, 285,   8,   1,\n",
       "       286,   4,   1,  60, 287, 288, 289, 290,   7,  49,   2, 291,   6,\n",
       "       292, 293,   1, 294, 295,   2, 296, 297, 298, 299,  10,  28,   2,\n",
       "       300, 301, 302, 303,  16,   1,  17,   6,  27,   2, 304, 305, 306,\n",
       "        10, 307, 308])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pad_input_seq[:,-1] #all last elements\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 27)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y = to_categorical(y , num_classes = 335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 335)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding , LSTM , Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">150,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">335</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,585</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m33,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)            │       \u001b[38;5;34m150,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m335\u001b[0m)            │        \u001b[38;5;34m50,585\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,685</span> (916.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m234,685\u001b[0m (916.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,685</span> (916.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m234,685\u001b[0m (916.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(335, 100, input_length=28, trainable=True))\n",
    "model.add(LSTM(150, input_shape=(28, 100)))\n",
    "model.add(Dense(335, activation='softmax'))\n",
    "model.build((None, 28))  # or add a sample input shape here\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = \"The ancient castle\"\n",
    "\n",
    "for i in range(15):\n",
    "#tokenize\n",
    "    token_text = tokenizer.texts_to_sequences([train_text])[0]\n",
    "\n",
    "#padding\n",
    "    padded_token_input = pad_sequences([token_text] , maxlen=28 , padding='pre')\n",
    "\n",
    "#predict\n",
    "    pos = np.argmax(model.predict(padded_token_input))\n",
    "\n",
    "    for word,index in tokenizer.word_index.items():\n",
    "        if index==pos:\n",
    "            train_text = train_text + \" \" + word\n",
    "            print(train_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
